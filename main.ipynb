{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd denoising\n",
    "!pip install -r requirements.txt\n",
    "!pip install --upgrade --no-cache-dir gdown\n",
    "!python3 setup.py develop --no_cuda_ext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "gdown.download('https://drive.google.com/uc?id=14Fht1QQJ2gMlk4N1ERCRuElg8JfjrWWR', \"./experiments/pretrained_models/\", quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from basicsr.models import create_model\n",
    "from basicsr.utils import img2tensor as _img2tensor, tensor2img, imwrite\n",
    "from basicsr.utils.options import parse\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imread(img_path):\n",
    "  img = cv2.imread(img_path)\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "  return img\n",
    "def img2tensor(img, bgr2rgb=False, float32=True):\n",
    "    img = img.astype(np.float32) / 255.\n",
    "    return _img2tensor(img, bgr2rgb=bgr2rgb, float32=float32)\n",
    "\n",
    "def display(img1, img2):\n",
    "  fig = plt.figure(figsize=(25, 10))\n",
    "  ax1 = fig.add_subplot(1, 2, 1) \n",
    "  plt.title('Input image', fontsize=16)\n",
    "  ax1.axis('off')\n",
    "  ax2 = fig.add_subplot(1, 2, 2)\n",
    "  plt.title('Denoised output', fontsize=16)\n",
    "  ax2.axis('off')\n",
    "  ax1.imshow(img1)\n",
    "  ax2.imshow(img2)\n",
    "\n",
    "def single_image_inference(model, img, save_path):\n",
    "  model.feed_data(data={'lq': img.unsqueeze(dim=0)})\n",
    "\n",
    "  if model.opt['val'].get('grids', False):\n",
    "    model.grids()\n",
    "\n",
    "  model.test()\n",
    "\n",
    "  if model.opt['val'].get('grids', False):\n",
    "    model.grids_inverse()\n",
    "\n",
    "  visuals = model.get_current_visuals()\n",
    "  sr_img = tensor2img([visuals['result']])\n",
    "  imwrite(sr_img, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_path = 'options/test/SIDD/NAFNet-width64.yml'\n",
    "opt = parse(opt_path, is_train=False)\n",
    "opt['dist'] = False\n",
    "denoising = create_model(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = '../input/image1.png'\n",
    "output_path = '../output/image1_denoised.png'\n",
    "\n",
    "img_input = imread(input_path)\n",
    "inp = img2tensor(img_input)\n",
    "single_image_inference(denoising, inp, output_path)\n",
    "img_output = imread(output_path)\n",
    "display(img_input, img_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deblurring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd '../deblurring'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 SDNet4.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 SDNet4_test.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
